<!DOCTYPE html>
<html lang="en" class="astro-EVFK6OE3">
	<head>
		<!-- Global Metadata --><meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<link rel="icon" type="image/svg+xml" href="/favicon.ico">
<meta name="generator" content="Astro v1.6.8">

<!-- Primary Meta Tags -->
<title>Machine Learning Final Project</title>
<meta name="title" content="Machine Learning Final Project">
<meta name="description">

<!-- Open Graph / Facebook -->
<!-- <meta property="og:type" content="website" />
<meta property="og:url" content={Astro.url} />
<meta property="og:title" content={title} />
<meta property="og:description" content={description} />
<meta property="og:image" content={new URL(image, Astro.url)} /> -->

<!-- Twitter -->
<!-- <meta property="twitter:card" content="summary_large_image" />
<meta property="twitter:url" content={Astro.url} />
<meta property="twitter:title" content={title} />
<meta property="twitter:description" content={description} />
<meta property="twitter:image" content={new URL(image, Astro.url)} /> -->

		
	<link rel="stylesheet" href="/assets/about.d6dc1795.css" />
<link rel="stylesheet" href="/assets/about.142b5762.css" /></head>

	<body class="astro-EVFK6OE3">
		
		<header class="astro-7F3CJDUI">
	<h2 class="astro-7F3CJDUI">
		Alexander Powers
	</h2>
	<h4 class="astro-7F3CJDUI">Engineer, Researcher, and ML Nerd.</h4>
	<nav class="astro-7F3CJDUI">
		<a href="/" class="astro-7F3CJDUI astro-FPRMATIO">
	Home
</a>

		<a href="/blog" class="astro-7F3CJDUI astro-FPRMATIO">
	Posts
</a>

		<a href="/about" class="astro-7F3CJDUI astro-FPRMATIO">
	About
</a>

		<a href="https://github.com/abpwrs" class="astro-7F3CJDUI astro-FPRMATIO" target="_blank">
	GitHub
</a>

	</nav>
</header>

		<main class="astro-EVFK6OE3">
			<article class="astro-EVFK6OE3">
				
				<h1 class="title astro-EVFK6OE3">Machine Learning Final Project</h1>
				<time class="astro-EVFK6OE3">Dec 28 2019</time>
				
				<hr class="astro-EVFK6OE3">
				<style>
    .caption {
        text-align:center
    }
</style>
<p>This semester, I took a machine learning and pattern recognition course. The final project for this course was an exploration of deep learning on the MNIST dataset, and an accuracy competition on the CIFAR10 dataset. <a href="https://github.com/abpwrs/ece-5450-fa19/blob/master/ml_project.ipynb">This</a> notebook goes through the entire final project assignment, however, this post will only go through the final transfer learning solution I submitted for the CIFAR10 competition.</p>
<p><img src="/blog/ml-final-project/viz.png" alt=""></p>
<p class="caption">Twenty Five Example Classifications</p>
<h1 id="cifar10">CIFAR10</h1>
<p>The CIFAR10 dataset consists of 60000 32x32 RGB images. Each of these images belongs to one of ten classes, with an evenly divided 6000 images per class. Additionally, 10000 of these samples are held out for cross validation.</p>
<h1 id="transfer-learning">Transfer Learning</h1>
<p>The intuition for transfer learning is that we can leverage knowledge gained through learning one task to more effectively and/or quickly learn another task. In practice, this is done by using the weights of a network trained on a different task as a starting point for training a new network. For this project I used the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG19?version=stable">VGG19 network</a> trained to classify <a href="http://www.image-net.org/">ImageNet</a> data. I chose this model because it ships with tensorflow and does not require upsampling the 32x32 images to a greater resolution. Below is the code that defines the model:</p>
<pre is:raw="" class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">transfer_model</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">VGG19(</span><span style="color: #FFA657">input_shape</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">32</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">32</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">), </span><span style="color: #FFA657">weights</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'imagenet'</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">include_top</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">False</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># set layers to non-trainable</span></span>
<span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> l </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> transfer_model.layers:</span></span>
<span class="line"><span style="color: #C9D1D9">    l.trainable </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">False</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transfer_model.output</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Flatten()(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">1024</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">512</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> BatchNormalization()(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">512</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">256</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> BatchNormalization()(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">256</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">128</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> BatchNormalization()(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">128</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">64</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> BatchNormalization()(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">64</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">64</span><span style="color: #C9D1D9">,</span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'relu'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dropout(</span><span style="color: #79C0FF">0.25</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"><span style="color: #C9D1D9">x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> BatchNormalization()(x)</span></span>
<span class="line"><span style="color: #C9D1D9">out </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Dense(</span><span style="color: #79C0FF">NUM_CLASSES</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">activation</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">'softmax'</span><span style="color: #C9D1D9">)(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">opt_model </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Model(</span><span style="color: #FFA657">inputs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">transfer_model.inputs, </span><span style="color: #FFA657">outputs</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">out)</span></span>
<span class="line"><span style="color: #C9D1D9">opt_model.compile(</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FFA657">optimizer</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">tf.keras.optimizers.Adam(</span><span style="color: #79C0FF">1e-3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FFA657">loss</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">tf.keras.losses.categorical_crossentropy,</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FFA657">metrics</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">[</span><span style="color: #A5D6FF">"accuracy"</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">"mse"</span><span style="color: #C9D1D9">],</span></span>
<span class="line"><span style="color: #C9D1D9">)</span></span></code></pre>
<p>The first round of training only trains the layers that we added to the end of the VGG19 network. We do this so that the training of the model specific layers doesnâ€™t degrade the quality of the weights in the pretrained network. This training last for 50 epochs:</p>
<p><img src="/blog/ml-final-project/first-training.png" alt=""></p>
<p class="caption">Loss and Accuracy Training on CIFAR10 Specific Layer Parameters</p>
<p>We then reset all layers to be trainable, and recompile the model with a lower learning rate. Then the entire model is retrained for 150 epochs, until the validation loss stopped decreasing.</p>
<pre is:raw="" class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> l </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> opt_model.layers:</span></span>
<span class="line"><span style="color: #C9D1D9">    l.trainable </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">True</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">opt_model.compile(</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FFA657">optimizer</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">tf.keras.optimizers.Adam(</span><span style="color: #79C0FF">1e-4</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FFA657">loss</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">tf.keras.losses.categorical_crossentropy,</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FFA657">metrics</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">[</span><span style="color: #A5D6FF">"accuracy"</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">"mse"</span><span style="color: #C9D1D9">],</span></span>
<span class="line"><span style="color: #C9D1D9">)</span></span></code></pre>
<p><img src="/blog/ml-final-project/second-training.png" alt=""></p>
<p class="caption">Loss and Accuracy Training on All Parameters</p>
<p>The visualization below give us further insight into the sources of error in the model. We can see in the confusion matrix below that classes three and five (cat and dog respectively) are getting being misclassified as the other.</p>
<p><img src="/blog/ml-final-project/cm.png" alt=""></p>
<p class="caption">Confusion Matrix Across the Ten Classes</p>
<p>I was able to achieve a final accuracy of <code>87.36%</code> on the validation data, placing my model in the top five of the class.</p>
			</article>
		</main>
		<footer class="astro-O7B7CN5A">
	&copy; 2022 Alexander Powers. All rights reserved.
</footer>

	</body></html>